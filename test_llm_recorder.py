#!/usr/bin/env python3
"""
æµ‹è¯•LLMè°ƒç”¨è®°å½•åŠŸèƒ½
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# åŠ è½½.envæ–‡ä»¶
try:
    from dotenv import load_dotenv
    env_file = project_root / ".env"
    if env_file.exists():
        load_dotenv(env_file)
        print(f"âœ… å·²åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_file}")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°.envæ–‡ä»¶: {env_file}")
        print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º.envæ–‡ä»¶å¹¶é…ç½®APIå¯†é’¥")
except ImportError:
    print("âš ï¸ æœªå®‰è£…python-dotenvï¼Œå°è¯•ä»ç³»ç»Ÿç¯å¢ƒå˜é‡è¯»å–")
except Exception as e:
    print(f"âš ï¸ åŠ è½½.envæ–‡ä»¶å¤±è´¥: {e}")

def check_api_keys():
    """æ£€æŸ¥APIå¯†é’¥é…ç½®"""
    print("\nğŸ”‘ æ£€æŸ¥APIå¯†é’¥é…ç½®:")
    
    api_keys = {
        'DEEPSEEK_API_KEY': os.getenv('DEEPSEEK_API_KEY'),
        'DASHSCOPE_API_KEY': os.getenv('DASHSCOPE_API_KEY'),
        'GOOGLE_API_KEY': os.getenv('GOOGLE_API_KEY'),
        'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY')
    }
    
    available_keys = []
    for key_name, key_value in api_keys.items():
        if key_value:
            print(f"   âœ… {key_name}: {key_value[:8]}...")
            available_keys.append(key_name)
        else:
            print(f"   âŒ {key_name}: æœªè®¾ç½®")
    
    if not available_keys:
        print("\nâš ï¸ æœªæ‰¾åˆ°ä»»ä½•APIå¯†é’¥ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®è‡³å°‘ä¸€ä¸ªAPIå¯†é’¥")
        print("ç¤ºä¾‹é…ç½®:")
        print("   DEEPSEEK_API_KEY=sk-your-deepseek-key")
        print("   DASHSCOPE_API_KEY=sk-your-dashscope-key")
        return False
    
    print(f"\nâœ… æ‰¾åˆ° {len(available_keys)} ä¸ªå¯ç”¨çš„APIå¯†é’¥")
    return True

def test_llm_recorder():
    """æµ‹è¯•LLMè®°å½•åŠŸèƒ½"""
    
    print("ğŸ§ª æµ‹è¯•LLMè°ƒç”¨è®°å½•åŠŸèƒ½")
    print("=" * 50)
    
    # æ£€æŸ¥APIå¯†é’¥
    if not check_api_keys():
        return
    
    # å¯ç”¨LLMè®°å½•
    os.environ['LLM_RECORD_ENABLED'] = 'true'
    
    # æµ‹è¯•ä¸åŒçš„é€‚é…å™¨
    adapters_to_test = [
        {
            'name': 'ChatDeepSeek',
            'module': 'tradingagents.llm_adapters.deepseek_adapter',
            'class': 'ChatDeepSeek',
            'api_key_env': 'DEEPSEEK_API_KEY',
            'model': 'deepseek-chat'
        },
        {
            'name': 'DeepSeekDirectAdapter',
            'module': 'tradingagents.llm_adapters.deepseek_direct_adapter',
            'class': 'DeepSeekDirectAdapter',
            'api_key_env': 'DEEPSEEK_API_KEY',
            'model': 'deepseek-chat'
        },
        {
            'name': 'ChatDashScopeOpenAI',
            'module': 'tradingagents.llm_adapters.dashscope_openai_adapter',
            'class': 'ChatDashScopeOpenAI',
            'api_key_env': 'DASHSCOPE_API_KEY',
            'model': 'qwen-turbo'
        }
    ]
    
    successful_tests = 0
    
    for adapter_config in adapters_to_test:
        print(f"\nğŸ”§ æµ‹è¯• {adapter_config['name']}...")
        
        # æ£€æŸ¥APIå¯†é’¥
        api_key = os.getenv(adapter_config['api_key_env'])
        if not api_key:
            print(f"âš ï¸ {adapter_config['api_key_env']}æœªè®¾ç½®ï¼Œè·³è¿‡æµ‹è¯•")
            continue
        
        try:
            # åŠ¨æ€å¯¼å…¥é€‚é…å™¨
            module = __import__(adapter_config['module'], fromlist=[adapter_config['class']])
            adapter_class = getattr(module, adapter_config['class'])
            
            # åˆ›å»ºLLMå®ä¾‹
            if adapter_config['name'] == 'DeepSeekDirectAdapter':
                llm = adapter_class(
                    model=adapter_config['model'],
                    temperature=0.1,
                    max_tokens=100
                )
            else:
                llm = adapter_class(
                    model=adapter_config['model'],
                    temperature=0.1,
                    max_tokens=100
                )
            
            # æµ‹è¯•è°ƒç”¨
            test_messages = [
                ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚"),
                ("human", "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‚¡ç¥¨æŠ•èµ„çš„åŸºæœ¬æ¦‚å¿µã€‚")
            ]
            
            if adapter_config['name'] == 'DeepSeekDirectAdapter':
                # ç›´æ¥é€‚é…å™¨ä½¿ç”¨ä¸åŒçš„æ¶ˆæ¯æ ¼å¼
                test_messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‚¡ç¥¨æŠ•èµ„çš„åŸºæœ¬æ¦‚å¿µã€‚"}
                ]
                response = llm.invoke(test_messages, session_id=f"test_{adapter_config['name']}", analysis_type="test")
                response_content = response
            else:
                response = llm.invoke(test_messages, session_id=f"test_{adapter_config['name']}", analysis_type="test")
                response_content = response.content
            
            print(f"âœ… {adapter_config['name']} è°ƒç”¨æˆåŠŸ")
            print(f"   å“åº”é•¿åº¦: {len(response_content)} å­—ç¬¦")
            print(f"   å“åº”é¢„è§ˆ: {response_content[:100]}...")
            
            successful_tests += 1
            
        except Exception as e:
            print(f"âŒ {adapter_config['name']} æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # æ£€æŸ¥è®°å½•
    print(f"\nğŸ“ æ£€æŸ¥è°ƒç”¨è®°å½•... (æˆåŠŸæµ‹è¯•: {successful_tests})")
    try:
        from tradingagents.utils.llm_call_recorder import get_llm_recorder
        
        recorder = get_llm_recorder()
        recent_records = recorder.get_recent_records(limit=successful_tests)
        
        if recent_records:
            print(f"âœ… æ‰¾åˆ° {len(recent_records)} æ¡æœ€æ–°è®°å½•:")
            
            for i, record in enumerate(recent_records):
                print(f"\nğŸ“‹ è®°å½• {i+1}:")
                print(f"   è®°å½•ID: {record['id']}")
                print(f"   æä¾›å•†: {record['provider']}")
                print(f"   æ¨¡å‹: {record['model']}")
                print(f"   ä¼šè¯ID: {record['session_id']}")
                print(f"   æ‰§è¡Œæ—¶é—´: {record['duration']:.2f}ç§’")
                print(f"   è¾“å…¥tokens: {record['input_tokens']}")
                print(f"   è¾“å‡ºtokens: {record['output_tokens']}")
                print(f"   æˆæœ¬: Â¥{record['cost']:.6f}")
                print(f"   æ–‡ä»¶: data/llm_records/{record['id']}.json")
            
        else:
            print("âŒ æœªæ‰¾åˆ°è°ƒç”¨è®°å½•")
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥è®°å½•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def show_usage():
    """æ˜¾ç¤ºä½¿ç”¨è¯´æ˜"""
    print("\n" + "=" * 60)
    print("ğŸ“– LLMè°ƒç”¨è®°å½•åŠŸèƒ½ä½¿ç”¨è¯´æ˜")
    print("=" * 60)
    print()
    print("1. å¯ç”¨è®°å½•åŠŸèƒ½:")
    print("   export LLM_RECORD_ENABLED=true")
    print()
    print("2. è¿è¡Œåˆ†æ:")
    print("   python your_analysis_script.py")
    print()
    print("3. æŸ¥çœ‹è®°å½•æ–‡ä»¶:")
    print("   ls data/llm_records/")
    print("   cat data/llm_records/deepseek_*.json")
    print()
    print("4. è®°å½•æ–‡ä»¶åŒ…å«:")
    print("   - å®Œæ•´çš„è¾“å…¥æ¶ˆæ¯ï¼ˆsystem + humanï¼‰")
    print("   - å®Œæ•´çš„è¾“å‡ºå“åº”")
    print("   - Tokenä½¿ç”¨é‡å’Œæˆæœ¬")
    print("   - æ‰§è¡Œæ—¶é—´å’Œä¸Šä¸‹æ–‡ä¿¡æ¯")
    print()
    print("5. æ”¯æŒçš„é€‚é…å™¨:")
    print("   âœ… ChatDeepSeek")
    print("   âœ… ChatDashScopeOpenAI")
    print("   ğŸ”„ å…¶ä»–é€‚é…å™¨å¯æŒ‰éœ€æ·»åŠ ")

if __name__ == "__main__":
    test_llm_recorder()
    show_usage()
